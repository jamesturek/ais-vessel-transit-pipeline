'contributors()'
'citation()'
'demo()'
demo()
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
if(!require("spatstat")) install.packages("spatstat")
if(!require("sf")) install.packages("sf")
if(!require("sf")) install.packages("sf")
if(!require("dplyr")) install.packages("dplyr")
if(!require("dplyr")) install.packages("dplyr")
if(!require("mapview")) install.packages("mapview")
path_to_folder <- "C:/Users/james/OneDrive/Desktop/GY476_Data/GY476_2025_GIS_Files_20250930/Inside_Airbnb"
# Load polygon shapefile with BA neighbourhoods
BA <- read_sf(paste0(path_to_folder, "neighbourhoods_BA_posgar.shp"))
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
fig.width = 10,
fig.height = 7,
fig.align = "center"
)
# Install packages if needed
packages <- c("sf", "tidyverse", "rvest", "httr", "jsonlite", "osmdata",
"tmap", "leaflet", "viridis", "scales", "ggrepel", "janitor",
"DT", "knitr")
installed <- packages %in% rownames(installed.packages())
if (any(!installed)) {
install.packages(packages[!installed])
}
library(sf)
library(tidyverse)
library(rvest)
library(httr)
library(jsonlite)
library(osmdata)
library(tmap)
library(leaflet)
library(viridis)
library(scales)
library(ggrepel)
library(janitor)
library(DT)
library(knitr)
# Create data directories
if (!dir.exists("data")) dir.create("data")
if (!dir.exists("outputs")) dir.create("outputs")
# Official GeoJSON from Barcelona Open Data
barris_url <- "https://opendata-ajuntament.barcelona.cat/data/dataset/808daafa-d9ce-48c0-925a-fa5afdb1ed41/resource/cd800462-f326-429f-a67a-c69b7fc4c50a/download/unitats_administratives_bcn.geojson"
barris <- st_read(barris_url, quiet = TRUE) %>%
# Filter to just neighbourhoods (not districts or census areas)
filter(TIPUS_UA == "BARRI") %>%
clean_names() %>%
select(codi_ua, nom, districte, area, geometry) %>%
rename(
barri_code = codi_ua,
barri_name = nom,
district_code = districte,
area_m2 = area
)
barris <- st_read(barris_url, quiet = TRUE) %>%
# Filter to just neighbourhoods (not districts or census areas)
filter(TIPUS_UA == "BARRI") %>%
clean_names() %>%
select(codi_ua, nom, districte, area, geometry) %>%
rename(
barri_code = codi_ua,
barri_name = nom,
district_code = districte,
area_m2 = area
)
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
fig.width = 10,
fig.height = 7,
fig.align = "center"
)
# Install packages if needed
packages <- c("sf", "tidyverse", "rvest", "httr", "jsonlite", "osmdata",
"tmap", "leaflet", "viridis", "scales", "ggrepel", "janitor",
"DT", "knitr")
installed <- packages %in% rownames(installed.packages())
if (any(!installed)) {
install.packages(packages[!installed])
}
library(sf)
library(tidyverse)
library(rvest)
library(httr)
library(jsonlite)
library(osmdata)
library(tmap)
library(leaflet)
library(viridis)
library(scales)
library(ggrepel)
library(janitor)
library(DT)
library(knitr)
# Create data directories
if (!dir.exists("data")) dir.create("data")
if (!dir.exists("outputs")) dir.create("outputs")
# GitHub repository with Barcelona geodata (reliable, no bot protection)
# Original source: Ajuntament de Barcelona / CartoBCN (CC-BY)
barris_url <- "https://raw.githubusercontent.com/martgnz/bcn-geodata/master/barris/barris.geojson"
barris <- st_read(barris_url, quiet = TRUE) %>%
clean_names() %>%
# The GitHub version already contains only barris
# Key columns: DISTRICTE (district code), NOM (name), AREA (m²)
select(districte, barri, nom, area, geometry) %>%
rename(
district_code = districte,
barri_code = barri,
barri_name = nom,
area_m2 = area
)
cat("Downloaded", nrow(barris), "neighbourhoods\n")
# Quick overview map
ggplot(barris) +
geom_sf(aes(fill = district_code), colour = "white", size = 0.2) +
scale_fill_viridis_d(option = "turbo", name = "District") +
theme_minimal() +
labs(title = "Barcelona Neighbourhoods by District") +
theme(
axis.text = element_blank(),
axis.ticks = element_blank(),
panel.grid = element_blank()
)
# Save locally for future use
st_write(barris, "data/barris.gpkg", delete_dsn = TRUE, quiet = TRUE)
# District-level rent estimates
# UPDATE THESE with latest Idealista/Fotocasa data
rent_by_district <- tribble(
~district_code, ~district_name, ~rent_eur_m2, ~avg_rent_1bed,
"01", "Ciutat Vella", 26.5, 1400,
"02", "Eixample", 24.5, 1450,
"03", "Sants-Montjuïc", 19.0, 1100,
"04", "Les Corts", 21.5, 1300,
"05", "Sarrià-Sant Gervasi", 23.0, 1500,
"06", "Gràcia", 22.5, 1250,
"07", "Horta-Guinardó", 16.5, 950,
"08", "Nou Barris", 15.5, 850,
"09", "Sant Andreu", 16.0, 900,
"10", "Sant Martí", 20.5, 1150
)
kable(rent_by_district, col.names = c("Code", "District", "€/m²", "Avg 1-bed (€)"))
scrape_idealista_barri <- function(barri_slug, max_pages = 3) {
Sys.sleep(runif(1, 2, 5))  # Rate limiting
base_url <- paste0("https://www.idealista.com/alquiler-viviendas/barcelona/",
barri_slug, "/")
listings <- list()
for (page in 1:max_pages) {
url <- if (page == 1) base_url else paste0(base_url, "pagina-", page, ".htm")
tryCatch({
page_html <- read_html(url)
items <- page_html %>% html_elements(".item-info-container")
for (item in items) {
price <- item %>%
html_element(".item-price") %>%
html_text() %>%
str_extract("\\d+\\.?\\d*") %>%
str_replace("\\.", "") %>%
as.numeric()
size <- item %>%
html_element(".item-detail") %>%
html_text() %>%
str_extract("\\d+") %>%
as.numeric()
if (!is.na(price) && !is.na(size) && size > 0) {
listings[[length(listings) + 1]] <- tibble(
price = price,
size_m2 = size,
price_per_m2 = price / size,
barri = barri_slug
)
}
}
Sys.sleep(runif(1, 1, 3))
}, error = function(e) {
message(paste("Error scraping", url))
})
}
if (length(listings) > 0) bind_rows(listings) else NULL
}
# Example:
# sant_antoni <- scrape_idealista_barri("sant-antoni")
# Barcelona bounding box
bcn_bbox <- st_bbox(barris)
# Helper function to download OSM data
get_bcn_osm <- function(key, value) {
message(paste("Downloading", key, "=", value, "..."))
osm_data <- opq(bbox = bcn_bbox) %>%
add_osm_feature(key = key, value = value) %>%
osmdata_sf()
if (!is.null(osm_data$osm_points) && nrow(osm_data$osm_points) > 0) {
return(osm_data$osm_points)
} else if (!is.null(osm_data$osm_polygons) && nrow(osm_data$osm_polygons) > 0) {
return(st_centroid(osm_data$osm_polygons))
}
return(NULL)
}
# Download amenities (cached to avoid repeated API calls)
supermarkets <- get_bcn_osm("shop", "supermarket")
setwd("C:/Users/james/OneDrive/Desktop/AIS Project/AISVesselTransitCounts2023")
knitr::opts_chunk$set(echo = TRUE)
dir.create("data/raw", recursive = TRUE)
dir.create("data/processed", recursive = TRUE)
dir.create("R")
install.packages(c("data.table", "dplyr", "DBI", "RSQLite", "lubridate", "janitor"))
ais_pipeline/
├── data/
dir.create("data/raw", recursive = TRUE)
dir.create("data/processed", recursive = TRUE)
dir.create("R")
install.packages(c("terra", "DBI", "RSQLite", "dplyr", "tibble"))
list.files("data/raw/", full.names = TRUE)
list.files("data/raw/", full.names = TRUE)
list.files("C:/Users/james/OneDrive/Desktop/AIS Project/AISVesselTransitCounts2023", full.names = TRUE)
library(terra)
atl <- rast("AISVTC2023Atlantic.tif")
atl
# peek at the metadata
readLines("AISVTC2023Atlantic.tif.xml", n = 50)
# 01_extract.R
# Extract: load AIS raster data, reproject, convert to dataframe
library(terra)
library(dplyr)
install.packages(c("rlang", "dplyr"))
